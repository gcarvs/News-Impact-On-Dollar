{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "Given that we trained and evaluated the models for each experiment with different hyperparameter combination, we are now going to perform a cross validation in the best models for each experiment, to have a more precise evaluation of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, model_selection\n",
    "from tensorflow import keras\n",
    "from tensorflow.metrics import precision\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "features = genfromtxt('../datasets/final-data/features.csv', delimiter=',')\n",
    "labels = genfromtxt('../datasets/final-data/labels.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best hyperparameter combination for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name             model_472\n",
       "units                         35\n",
       "learning_rate               0.01\n",
       "momentum                  0.0001\n",
       "decay                     0.0001\n",
       "activation_function         relu\n",
       "acc                     0.558249\n",
       "loss                    0.717674\n",
       "mae                          0.5\n",
       "mse                     0.275367\n",
       "precision               0.549315\n",
       "recall                  0.629513\n",
       "fs_score                0.586686\n",
       "Name: 471, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = [dI for dI in os.listdir('../experiments') if os.path.isdir(os.path.join('../experiments',dI))]\n",
    "\n",
    "best_models = []\n",
    "for experiment in experiments:\n",
    "    training_metrics = pd.read_csv('../experiments/' + experiment + '/training_metrics.csv')\n",
    "    training_metrics = training_metrics.sort_values(['acc', 'precision', 'recall'], ascending=[False, False, False])\n",
    "    best_model = training_metrics.iloc[0]\n",
    "    best_model[\"experiment\"] = experiment\n",
    "    \n",
    "    best_models.append(best_model)\n",
    "    \n",
    "best_models = pd.DataFrame(best_models).reset_index().drop(columns=['index'])\n",
    "best_models = best_models.sort_values(['experiment'], ascending=True)\n",
    "best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model construct function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(units, activation_function, learning_rate, decay, momentum):\n",
    "    #Creating the network structure\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(keras.layers.Input(shape=300,sparse=False))\n",
    "    model.add(keras.layers.Dense(150))\n",
    "    model.add(keras.layers.Dense(units, activation = activation_function))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    # Setting the optimizers parameters\n",
    "    optimizer = tf.keras.optimizers.SGD(\n",
    "        learning_rate=learning_rate,\n",
    "        decay=decay,\n",
    "        momentum=momentum,\n",
    "        nesterov=True\n",
    "    )\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(\n",
    "        optimizer = optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['acc', 'mae', 'mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_x, \n",
    "        train_y, \n",
    "        epochs = 1, \n",
    "        validation_split=0.3, \n",
    "        batch_size = 16,  \n",
    "        verbose=1, \n",
    "        use_multiprocessing=True,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def test_model(model, test_x, test_y):\n",
    "    loss, acc, mae, mse = model.evaluate(test_x, test_y, verbose=1)\n",
    "    \n",
    "    test_output_probabilities = model.predict(\n",
    "        test_x,\n",
    "        batch_size=16,\n",
    "        verbose=1,\n",
    "        steps=None,\n",
    "        callbacks=None,\n",
    "        max_queue_size=10,\n",
    "        workers=1,\n",
    "        use_multiprocessing=True\n",
    "    )\n",
    "    \n",
    "    predicted_y = np.argmax(test_output_probabilities, axis=1)\n",
    "    \n",
    "    precision, recall, f_score, support = precision_recall_fscore_support(\n",
    "        y_true = test_y, \n",
    "        y_pred = predicted_y, \n",
    "        average = 'binary'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"loss\": loss,\n",
    "        \"acc\": acc,\n",
    "        \"mae\": mae,\n",
    "        \"mse\": mse,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f_score\": f_score\n",
    "    }\n",
    "\n",
    "def compute_c_validated_matrics(best_model, test_results):\n",
    "    return {\n",
    "        \"model_name\": best_model[\"model_name\"],\n",
    "        \"units\": best_model[\"units\"], \n",
    "        \"learning_rate\": best_model[\"learning_rate\"], \n",
    "        \"momentum\": best_model[\"momentum\"],\n",
    "        \"decay\": best_model[\"decay\"],\n",
    "        \"activation_function\": best_model[\"activation_function\"],\n",
    "        \"average_acc\": cross_validation_df[\"acc\"].mean(),\n",
    "        \"acc_std_deviation\": cross_validation_df[\"acc\"].std(),\n",
    "        \"average_precision\": cross_validation_df[\"precision\"].mean(),\n",
    "        \"precision_std_deviation\": cross_validation_df[\"precision\"].std(),\n",
    "        \"average_recall\": cross_validation_df[\"recall\"].mean(),\n",
    "        \"recall_std_deviation\": cross_validation_df[\"recall\"].std(),\n",
    "        \"average_fs_score\": cross_validation_df[\"f_score\"].mean(),\n",
    "        \"fs_score_std_deviation\": cross_validation_df[\"f_score\"].std()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0513 20:57:30.863578 4670819776 deprecation.py:506] From /Users/gcarvs/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3081 samples, validate on 1321 samples\n",
      "3081/3081 [==============================] - 2s 633us/sample - loss: 0.7679 - acc: 0.5080 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2837 - val_loss: 0.6981 - val_acc: 0.4943 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2518\n",
      "490/490 [==============================] - 0s 78us/sample - loss: 0.6887 - acc: 0.5367 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2518\n",
      "490/490 [==============================] - 0s 196us/sample\n",
      "Train on 3081 samples, validate on 1321 samples\n",
      "3081/3081 [==============================] - 2s 535us/sample - loss: 0.7639 - acc: 0.4998 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2778 - val_loss: 0.6957 - val_acc: 0.5049 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2512\n",
      "490/490 [==============================] - 0s 82us/sample - loss: 0.6861 - acc: 0.5633 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2518\n",
      "490/490 [==============================] - 0s 193us/sample\n",
      "Train on 3082 samples, validate on 1321 samples\n",
      "3082/3082 [==============================] - 1s 441us/sample - loss: 0.7536 - acc: 0.5052 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2795 - val_loss: 0.6982 - val_acc: 0.4731 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2516\n",
      "489/489 [==============================] - 0s 143us/sample - loss: 0.6920 - acc: 0.5501 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2517\n",
      "489/489 [==============================] - 0s 236us/sample\n",
      "Train on 3082 samples, validate on 1321 samples\n",
      "3082/3082 [==============================] - 2s 573us/sample - loss: 0.7650 - acc: 0.5178 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2841 - val_loss: 0.6931 - val_acc: 0.5208 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2514\n",
      "489/489 [==============================] - 0s 126us/sample - loss: 0.6984 - acc: 0.4928 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2516\n",
      "489/489 [==============================] - 0s 234us/sample\n",
      "Train on 3082 samples, validate on 1321 samples\n",
      "3082/3082 [==============================] - 1s 451us/sample - loss: 0.7711 - acc: 0.5123 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2846 - val_loss: 0.6913 - val_acc: 0.5269 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2518\n",
      "489/489 [==============================] - 0s 135us/sample - loss: 0.7034 - acc: 0.4744 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2519\n",
      "489/489 [==============================] - 0s 234us/sample\n",
      "Train on 3082 samples, validate on 1321 samples\n",
      "3082/3082 [==============================] - 1s 483us/sample - loss: 0.7887 - acc: 0.5097 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2883 - val_loss: 0.6983 - val_acc: 0.5322 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2561\n",
      "489/489 [==============================] - 0s 151us/sample - loss: 0.7234 - acc: 0.4254 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2551\n",
      "489/489 [==============================] - 0s 369us/sample\n",
      "Train on 3082 samples, validate on 1321 samples\n",
      "3082/3082 [==============================] - 1s 473us/sample - loss: 0.7516 - acc: 0.5185 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2793 - val_loss: 0.6975 - val_acc: 0.4913 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2515\n",
      "489/489 [==============================] - 0s 114us/sample - loss: 0.6946 - acc: 0.5112 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2515\n",
      "489/489 [==============================] - 0s 309us/sample\n",
      "Train on 3082 samples, validate on 1321 samples\n",
      "3082/3082 [==============================] - 2s 497us/sample - loss: 0.7535 - acc: 0.5123 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2797 - val_loss: 0.6941 - val_acc: 0.5087 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2513\n",
      "489/489 [==============================] - 0s 117us/sample - loss: 0.7017 - acc: 0.4949 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2513\n",
      "489/489 [==============================] - 0s 316us/sample\n",
      "Train on 3082 samples, validate on 1321 samples\n",
      "3082/3082 [==============================] - 2s 519us/sample - loss: 0.7358 - acc: 0.5127 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2722 - val_loss: 0.7000 - val_acc: 0.4739 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2510\n",
      "489/489 [==============================] - 0s 144us/sample - loss: 0.6884 - acc: 0.5521 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2511\n",
      "489/489 [==============================] - 0s 430us/sample\n",
      "Train on 3082 samples, validate on 1321 samples\n",
      "3082/3082 [==============================] - 2s 585us/sample - loss: 0.7406 - acc: 0.5237 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2771 - val_loss: 0.6926 - val_acc: 0.5178 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2512\n",
      "489/489 [==============================] - 0s 141us/sample - loss: 0.6911 - acc: 0.5337 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2513\n",
      "489/489 [==============================] - 0s 526us/sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'model_472',\n",
       " 'units': 35,\n",
       " 'learning_rate': 0.01,\n",
       " 'momentum': 0.0001,\n",
       " 'decay': 0.0001,\n",
       " 'activation_function': 'relu',\n",
       " 'average_acc': 0.5134764790534974,\n",
       " 'acc_std_deviation': 0.04259974785770258,\n",
       " 'average_precision': 0.5138952312136836,\n",
       " 'precision_std_deviation': 0.09282376048905862,\n",
       " 'average_recall': 0.4324116907822996,\n",
       " 'recall_std_deviation': 0.2531903317732664,\n",
       " 'average_fs_score': 0.4299808844098994,\n",
       " 'fs_score_std_deviation': 0.1790100842132491}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validated_models = []\n",
    "\n",
    "for best_model in best_models:\n",
    "    cross_validation_results = []\n",
    "\n",
    "    # We used k = 10 as it's the general number used in the literature\n",
    "    for train_index,test_index in KFold(n_splits=10, random_state=None, shuffle=False).split(features):\n",
    "        train_x, test_x = features[train_index], features[test_index]\n",
    "        train_y, test_y = labels[train_index], labels[test_index]\n",
    "\n",
    "        model = create_model(\n",
    "            best_model['units'], \n",
    "            best_model['activation_function'], \n",
    "            best_model['learning_rate'],\n",
    "            best_model['decay'],\n",
    "            best_model['momentum'])\n",
    "\n",
    "        history = train_model(model)\n",
    "        test_results = test_model(model, test_x, test_y)\n",
    "\n",
    "        cross_validation_results.append(\n",
    "            {\n",
    "                \"model_name\": best_model[\"model_name\"],\n",
    "                \"units\": best_model[\"units\"], \n",
    "                \"learning_rate\": best_model[\"learning_rate\"], \n",
    "                \"momentum\": best_model[\"momentum\"],\n",
    "                \"decay\": best_model[\"decay\"],\n",
    "                \"activation_function\": best_model[\"activation_function\"],\n",
    "                \"acc\": test_results[\"acc\"],\n",
    "                \"precision\": test_results[\"precision\"],\n",
    "                \"recall\": test_results[\"recall\"],\n",
    "                \"f_score\": test_results[\"f_score\"] \n",
    "            }\n",
    "        )\n",
    "\n",
    "    cross_validation_df = pd.DataFrame(cross_validation_results)\n",
    "\n",
    "    cross_validated_metrics = compute_c_validated_matrics(best_model, test_results)\n",
    "\n",
    "    cross_validated_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>decay</th>\n",
       "      <th>f_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>model_name</th>\n",
       "      <th>momentum</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.536735</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.450363</td>\n",
       "      <td>0.01</td>\n",
       "      <td>model_472</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.451456</td>\n",
       "      <td>0.449275</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.563265</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.291391</td>\n",
       "      <td>0.01</td>\n",
       "      <td>model_472</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.463158</td>\n",
       "      <td>0.212560</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.550102</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.01</td>\n",
       "      <td>model_472</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.549872</td>\n",
       "      <td>0.830116</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.492843</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>0.01</td>\n",
       "      <td>model_472</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.584541</td>\n",
       "      <td>0.427562</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.474438</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.349367</td>\n",
       "      <td>0.01</td>\n",
       "      <td>model_472</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.518797</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.425358</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.090615</td>\n",
       "      <td>0.01</td>\n",
       "      <td>model_472</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.049123</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.511247</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.590051</td>\n",
       "      <td>0.01</td>\n",
       "      <td>model_472</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.494888</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.529524</td>\n",
       "      <td>0.01</td>\n",
       "      <td>model_472</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.441270</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.552147</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.01</td>\n",
       "      <td>model_472</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.201058</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.533742</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.585455</td>\n",
       "      <td>0.01</td>\n",
       "      <td>model_472</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.688034</td>\n",
       "      <td>0.509494</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc activation_function   decay   f_score  learning_rate model_name  \\\n",
       "0  0.536735                relu  0.0001  0.450363           0.01  model_472   \n",
       "1  0.563265                relu  0.0001  0.291391           0.01  model_472   \n",
       "2  0.550102                relu  0.0001  0.661538           0.01  model_472   \n",
       "3  0.492843                relu  0.0001  0.493878           0.01  model_472   \n",
       "4  0.474438                relu  0.0001  0.349367           0.01  model_472   \n",
       "5  0.425358                relu  0.0001  0.090615           0.01  model_472   \n",
       "6  0.511247                relu  0.0001  0.590051           0.01  model_472   \n",
       "7  0.494888                relu  0.0001  0.529524           0.01  model_472   \n",
       "8  0.552147                relu  0.0001  0.257627           0.01  model_472   \n",
       "9  0.533742                relu  0.0001  0.585455           0.01  model_472   \n",
       "\n",
       "   momentum  precision    recall  units  \n",
       "0    0.0001   0.451456  0.449275     35  \n",
       "1    0.0001   0.463158  0.212560     35  \n",
       "2    0.0001   0.549872  0.830116     35  \n",
       "3    0.0001   0.584541  0.427562     35  \n",
       "4    0.0001   0.518797  0.263359     35  \n",
       "5    0.0001   0.583333  0.049123     35  \n",
       "6    0.0001   0.500000  0.719665     35  \n",
       "7    0.0001   0.441270  0.661905     35  \n",
       "8    0.0001   0.358491  0.201058     35  \n",
       "9    0.0001   0.688034  0.509494     35  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cross_validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
