{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "from numpy import genfromtxt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv('../experiments/experiment_lstm_title/train_y.csv')\n",
    "test_y = pd.read_csv('../experiments/experiment_lstm_title/test_y.csv')\n",
    "\n",
    "lt.style.use('seaborn-deep')\n",
    "\n",
    "x = [0, 1]\n",
    "bins = np.linspace(0, 1, 1000)\n",
    "\n",
    "plt.hist([x, train_y], bins, label=['x', 'y'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics = pd.read_csv('../experiments/experiment_lstm_title/training_metrics.csv')\n",
    "\n",
    "training_metrics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics = training_metrics.sort_values(['acc', 'precision', 'recall'], ascending=[False, False, False])\n",
    "\n",
    "training_metrics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = training_metrics.iloc[0]\n",
    "\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y = genfromtxt('../experiments/experiment_lstm_title/test_y.csv', delimiter=',')\n",
    "output_probabilities = genfromtxt('../experiments/experiment_lstm_title/trained_models/' + best_model[\"model_name\"] + '/test_output_probabilities.csv', delimiter=',')\n",
    "\n",
    "probas_pred = output_probabilities[...,1]\n",
    "\n",
    "average_precision = average_precision_score(true_y, probas_pred)\n",
    "precision, recall, _ = precision_recall_curve(true_y, probas_pred)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Dollar rate classification(LSTM + news title): AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_rf, tpr_rf, _ = roc_curve(true_y, probas_pred)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.xlim([-0.01, 1.00])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.plot(fpr_rf, tpr_rf, lw=1, label='{} curve (AUC = {:0.2f})'.format('RF',roc_auc_rf))\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
