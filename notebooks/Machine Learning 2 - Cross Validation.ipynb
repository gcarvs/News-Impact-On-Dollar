{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "Given that we trained and evaluated the models for each experiment with different hyperparameter combination, we are now going to perform a cross validation in the best models for each experiment, to have a more precise evaluation of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, model_selection\n",
    "from tensorflow import keras\n",
    "from tensorflow.metrics import precision\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "features = genfromtxt('../datasets/final-data/features.csv', delimiter=',')\n",
    "labels = genfromtxt('../datasets/final-data/labels.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best hyperparameter combination for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gcarvs/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/gcarvs/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:1015: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc[key] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>units</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>momentum</th>\n",
       "      <th>decay</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fs_score</th>\n",
       "      <th>experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>model_536</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.556685</td>\n",
       "      <td>0.809226</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.314087</td>\n",
       "      <td>0.549858</td>\n",
       "      <td>0.605965</td>\n",
       "      <td>0.576550</td>\n",
       "      <td>pmean_title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>model_345</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.548084</td>\n",
       "      <td>0.895111</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.329349</td>\n",
       "      <td>0.547812</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.539075</td>\n",
       "      <td>pmean_body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>model_262</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.578577</td>\n",
       "      <td>0.686320</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.262988</td>\n",
       "      <td>0.579032</td>\n",
       "      <td>0.563579</td>\n",
       "      <td>0.571201</td>\n",
       "      <td>mean_body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>model_224</td>\n",
       "      <td>75</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.542611</td>\n",
       "      <td>0.736829</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.284417</td>\n",
       "      <td>0.548327</td>\n",
       "      <td>0.463108</td>\n",
       "      <td>0.502128</td>\n",
       "      <td>pmean_title_subtitle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>model_472</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.558249</td>\n",
       "      <td>0.717674</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.275367</td>\n",
       "      <td>0.549315</td>\n",
       "      <td>0.629513</td>\n",
       "      <td>0.586686</td>\n",
       "      <td>mean_title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>model_448</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.541830</td>\n",
       "      <td>0.704175</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.262183</td>\n",
       "      <td>0.550495</td>\n",
       "      <td>0.436421</td>\n",
       "      <td>0.486865</td>\n",
       "      <td>mean_title_subtitle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name  units  learning_rate  momentum   decay activation_function  \\\n",
       "535  model_536     35         0.0001    0.1000  0.0001                relu   \n",
       "344  model_345     75         0.0001    0.1000  0.1000                relu   \n",
       "261  model_262     75         0.0100    0.0100  0.0100                relu   \n",
       "223  model_224     75         0.1000    0.0010  0.0001                relu   \n",
       "471  model_472     35         0.0100    0.0001  0.0001                relu   \n",
       "447  model_448     35         0.0100    0.0100  0.0001                relu   \n",
       "\n",
       "          acc      loss  mae       mse  precision    recall  fs_score  \\\n",
       "535  0.556685  0.809226  0.5  0.314087   0.549858  0.605965  0.576550   \n",
       "344  0.548084  0.895111  0.5  0.329349   0.547812  0.530612  0.539075   \n",
       "261  0.578577  0.686320  0.5  0.262988   0.579032  0.563579  0.571201   \n",
       "223  0.542611  0.736829  0.5  0.284417   0.548327  0.463108  0.502128   \n",
       "471  0.558249  0.717674  0.5  0.275367   0.549315  0.629513  0.586686   \n",
       "447  0.541830  0.704175  0.5  0.262183   0.550495  0.436421  0.486865   \n",
       "\n",
       "               experiment  \n",
       "535           pmean_title  \n",
       "344            pmean_body  \n",
       "261             mean_body  \n",
       "223  pmean_title_subtitle  \n",
       "471            mean_title  \n",
       "447   mean_title_subtitle  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = [dI for dI in os.listdir('../experiments') if os.path.isdir(os.path.join('../experiments',dI))]\n",
    "\n",
    "best_models = []\n",
    "for experiment in experiments:\n",
    "    training_metrics = pd.read_csv('../experiments/' + experiment + '/training_metrics.csv')\n",
    "    training_metrics = training_metrics.sort_values(['acc', 'precision', 'recall'], ascending=[False, False, False])\n",
    "    best_model = training_metrics.iloc[0]\n",
    "    best_model[\"experiment\"] = experiment\n",
    "    \n",
    "    best_models.append(best_model)\n",
    "    \n",
    "pd.DataFrame(best_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the helping functions\n",
    "\n",
    "Here we are going to define five helper functions for the cross validation process:\n",
    "\n",
    "1. create_model: creates a Keras model using the specified parameters\n",
    "2. train_model: trains the models using the train dataset\n",
    "3. test_model: tests the trained model using the test dataset\n",
    "4. compute_c_validated_metrics: Computes the average and standard deviation of each metric\n",
    "5. shuffle_dataset: shuffles the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, units, activation_function, learning_rate, decay, momentum):\n",
    "    linear_layer_size = 150\n",
    "    if \"pmean\" in model_name:\n",
    "        linear_layer_size = 450\n",
    "    #Creating the network structure\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(keras.layers.Input(shape=300,sparse=False))\n",
    "    model.add(keras.layers.Dense(linear_layer_size))\n",
    "    model.add(keras.layers.Dense(units, activation = activation_function))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    # Setting the optimizers parameters\n",
    "    optimizer = tf.keras.optimizers.SGD(\n",
    "        learning_rate=learning_rate,\n",
    "        decay=decay,\n",
    "        momentum=momentum,\n",
    "        nesterov=True\n",
    "    )\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(\n",
    "        optimizer = optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['acc', 'mae', 'mse'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, train_x, train_y):\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_x, \n",
    "        train_y, \n",
    "        epochs = 40, \n",
    "        validation_split=0.3, \n",
    "        batch_size = 16,  \n",
    "        verbose=1, \n",
    "        use_multiprocessing=True,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def test_model(model, test_x, test_y):\n",
    "    loss, acc, mae, mse = model.evaluate(test_x, test_y, verbose=1)\n",
    "    \n",
    "    test_output_probabilities = model.predict(\n",
    "        test_x,\n",
    "        batch_size=16,\n",
    "        verbose=1,\n",
    "        steps=None,\n",
    "        callbacks=None,\n",
    "        max_queue_size=10,\n",
    "        workers=1,\n",
    "        use_multiprocessing=True\n",
    "    )\n",
    "    \n",
    "    predicted_y = np.argmax(test_output_probabilities, axis=1)\n",
    "    \n",
    "    average_precision = average_precision_score(test_y, predicted_y)\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(test_y, predicted_y)\n",
    "    \n",
    "    fpr_rf, tpr_rf, _ = roc_curve(test_y, predicted_y)\n",
    "    roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "    \n",
    "    precision, recall, f_score, support = precision_recall_fscore_support(\n",
    "        y_true = test_y, \n",
    "        y_pred = predicted_y, \n",
    "        average = 'binary'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"loss\": loss,\n",
    "        \"acc\": acc,\n",
    "        \"mae\": mae,\n",
    "        \"mse\": mse,\n",
    "        \"test_y\": test_y,\n",
    "        \"predicted_y\": predicted_y,\n",
    "        \"precision_curve\": precision_curve,\n",
    "        \"recall_curve\": recall_curve,\n",
    "        \"average_precision\": average_precision,\n",
    "        \"fpr_rf\": fpr_rf,\n",
    "        \"tpr_rf\": tpr_rf,\n",
    "        \"roc_auc_rf\": roc_auc_rf,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f_score\": f_score\n",
    "    }\n",
    "\n",
    "def compute_c_validated_matrics(best_model, test_results):\n",
    "    experiment_folder = \"../cross_validation/\" + best_model[\"experiment\"]\n",
    "    if not os.path.exists(experiment_folder):\n",
    "        os.mkdir(experiment_folder)\n",
    "    \n",
    "    final_test_y = np.concatenate(test_results[\"test_y\"], axis=0)\n",
    "    np.savetxt(experiment_folder + \"/true_y.csv\", final_test_y, delimiter=\",\")\n",
    "    \n",
    "    final_predicted_y = np.concatenate(test_results[\"predicted_y\"], axis=0)\n",
    "    np.savetxt(experiment_folder + \"/predicted_y.csv\", final_predicted_y, delimiter=\",\")\n",
    "    \n",
    "    final_precision_curve = np.concatenate(test_results[\"precision_curve\"], axis=0)\n",
    "    np.savetxt(experiment_folder + \"/precision_curve.csv\", final_precision_curve, delimiter=\",\")\n",
    "    \n",
    "    final_recall_curve = np.concatenate(test_results[\"recall_curve\"], axis=0)\n",
    "    np.savetxt(experiment_folder + \"/recall_curve.csv\", final_recall_curve, delimiter=\",\")\n",
    "    \n",
    "    final_fpr_rf = np.concatenate(test_results[\"fpr_rf\"], axis=0)\n",
    "    np.savetxt(experiment_folder + \"/fpr_rf.csv\", final_fpr_rf, delimiter=\",\")\n",
    "    \n",
    "    final_tpr_rf = np.concatenate(test_results[\"tpr_rf\"], axis=0)\n",
    "    np.savetxt(experiment_folder + \"/tpr_rf.csv\", final_tpr_rf, delimiter=\",\")\n",
    "    \n",
    "    return {\n",
    "        \"experiment\": best_model[\"experiment\"],\n",
    "        \"model_name\": best_model[\"model_name\"],\n",
    "        \"units\": best_model[\"units\"], \n",
    "        \"learning_rate\": best_model[\"learning_rate\"], \n",
    "        \"momentum\": best_model[\"momentum\"],\n",
    "        \"decay\": best_model[\"decay\"],\n",
    "        \"activation_function\": best_model[\"activation_function\"],\n",
    "        \"average_acc\": test_results[\"acc\"].mean(),\n",
    "        \"acc_std_deviation\": test_results[\"acc\"].std(),\n",
    "        \"average_precision\": test_results[\"precision\"].mean(),\n",
    "        \"precision_std_deviation\": test_results[\"precision\"].std(),\n",
    "        \"average_recall\": test_results[\"recall\"].mean(),\n",
    "        \"recall_std_deviation\": test_results[\"recall\"].std(),\n",
    "        \"average_fs_score\": test_results[\"f_score\"].mean(),\n",
    "        \"fs_score_std_deviation\": test_results[\"f_score\"].std(),\n",
    "        \"average_precision_curve\": test_results[\"average_precision\"].mean(),\n",
    "        \"roc_auc_rf\": test_results[\"roc_auc_rf\"].mean()\n",
    "    }\n",
    "\n",
    "def shuffle_dataset(features, labels):\n",
    "    shuffled_indexes = np.arange(len(features))\n",
    "    np.random.shuffle(shuffled_indexes)\n",
    "    shuffled_features = []\n",
    "    shuffled_lables = []\n",
    "    for index in shuffled_indexes:\n",
    "        shuffled_features.append(features[index])\n",
    "        shuffled_lables.append(labels[index])\n",
    "    \n",
    "    return np.array(shuffled_features), np.array(shuffled_lables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validate the models\n",
    "\n",
    "Each model will be cross validated using 10 folders of the data, and then we will compute the cross validated metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0526 20:21:35.712016 4614028736 deprecation.py:506] From /Users/gcarvs/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmean_title\n",
      "Train on 1712 samples, validate on 734 samples\n",
      "1712/1712 [==============================] - 1s 664us/sample - loss: 0.8524 - acc: 0.5199 - mean_absolute_error: 0.5000 - mean_squared_error: 0.3123 - val_loss: 0.6971 - val_acc: 0.5095 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2515\n",
      "2446/2446 [==============================] - 0s 94us/sample - loss: 0.6967 - acc: 0.5090 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2516\n",
      "2446/2446 [==============================] - 0s 138us/sample\n",
      "1\n",
      "Train on 1712 samples, validate on 734 samples\n",
      "1712/1712 [==============================] - 1s 674us/sample - loss: 0.8333 - acc: 0.5058 - mean_absolute_error: 0.5000 - mean_squared_error: 0.3016 - val_loss: 0.6953 - val_acc: 0.5123 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2517\n",
      "2446/2446 [==============================] - 0s 97us/sample - loss: 0.6963 - acc: 0.5098 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2517\n",
      "2446/2446 [==============================] - 0s 144us/sample\n",
      "2\n",
      "pmean_body\n",
      "Train on 1712 samples, validate on 734 samples\n",
      "1712/1712 [==============================] - 2s 974us/sample - loss: 0.8094 - acc: 0.4848 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2905 - val_loss: 0.6959 - val_acc: 0.4891 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2507\n",
      "2446/2446 [==============================] - 0s 97us/sample - loss: 0.6953 - acc: 0.4869 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2507\n",
      "2446/2446 [==============================] - 0s 153us/sample\n",
      "1\n",
      "Train on 1712 samples, validate on 734 samples\n",
      "1712/1712 [==============================] - 1s 736us/sample - loss: 0.8627 - acc: 0.5216 - mean_absolute_error: 0.5000 - mean_squared_error: 0.3110 - val_loss: 0.6993 - val_acc: 0.4932 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2515\n",
      "2446/2446 [==============================] - 0s 102us/sample - loss: 0.6995 - acc: 0.4836 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2515\n",
      "2446/2446 [==============================] - 0s 147us/sample\n",
      "2\n",
      "mean_body\n",
      "Train on 1712 samples, validate on 734 samples\n",
      "1712/1712 [==============================] - 1s 732us/sample - loss: 0.7654 - acc: 0.5070 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2824 - val_loss: 0.6960 - val_acc: 0.4850 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2509\n",
      "2446/2446 [==============================] - 0s 83us/sample - loss: 0.6949 - acc: 0.4980 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2509\n",
      "2446/2446 [==============================] - 0s 176us/sample\n",
      "1\n",
      "Train on 1712 samples, validate on 734 samples\n",
      "1712/1712 [==============================] - 1s 743us/sample - loss: 0.8085 - acc: 0.4988 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2898 - val_loss: 0.6910 - val_acc: 0.5327 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2507\n",
      "2446/2446 [==============================] - 0s 98us/sample - loss: 0.6918 - acc: 0.5253 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2507\n",
      "2446/2446 [==============================] - 0s 141us/sample\n",
      "2\n",
      "pmean_title_subtitle\n",
      "Train on 1712 samples, validate on 734 samples\n",
      "1712/1712 [==============================] - 2s 921us/sample - loss: 0.7692 - acc: 0.5199 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2829 - val_loss: 0.6932 - val_acc: 0.5177 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2508\n",
      "2446/2446 [==============================] - 0s 133us/sample - loss: 0.6940 - acc: 0.4988 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2509\n",
      "2446/2446 [==============================] - 1s 230us/sample\n",
      "1\n",
      "Train on 1712 samples, validate on 734 samples\n",
      "1712/1712 [==============================] - 2s 915us/sample - loss: 0.7278 - acc: 0.5152 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2700 - val_loss: 0.6941 - val_acc: 0.4959 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2502\n",
      "2446/2446 [==============================] - 0s 115us/sample - loss: 0.6934 - acc: 0.5139 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2502\n",
      "2446/2446 [==============================] - 1s 237us/sample\n",
      "2\n",
      "mean_title\n",
      "Train on 1712 samples, validate on 734 samples\n",
      "1712/1712 [==============================] - 2s 886us/sample - loss: 0.8035 - acc: 0.4936 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2889 - val_loss: 0.7027 - val_acc: 0.4959 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2531\n",
      "2446/2446 [==============================] - 0s 96us/sample - loss: 0.6965 - acc: 0.5086 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2531\n",
      "2446/2446 [==============================] - 0s 196us/sample\n",
      "1\n",
      "Train on 1712 samples, validate on 734 samples\n",
      "1712/1712 [==============================] - 2s 880us/sample - loss: 0.7799 - acc: 0.5076 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2858 - val_loss: 0.6910 - val_acc: 0.5286 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2507\n",
      "2446/2446 [==============================] - 0s 96us/sample - loss: 0.6934 - acc: 0.5057 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2507\n",
      "2446/2446 [==============================] - 1s 246us/sample\n",
      "2\n",
      "mean_title_subtitle\n",
      "Train on 1712 samples, validate on 734 samples\n",
      "1712/1712 [==============================] - 2s 1ms/sample - loss: 0.8156 - acc: 0.5129 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2987 - val_loss: 0.6918 - val_acc: 0.5150 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2523\n",
      "2446/2446 [==============================] - 1s 209us/sample - loss: 0.6963 - acc: 0.5033 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2523\n",
      "2446/2446 [==============================] - 1s 221us/sample\n",
      "1\n",
      "Train on 1712 samples, validate on 734 samples\n",
      "1712/1712 [==============================] - 2s 929us/sample - loss: 0.7702 - acc: 0.5064 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2818 - val_loss: 0.6945 - val_acc: 0.4986 - val_mean_absolute_error: 0.5000 - val_mean_squared_error: 0.2518\n",
      "2446/2446 [==============================] - 0s 128us/sample - loss: 0.6958 - acc: 0.5008 - mean_absolute_error: 0.5000 - mean_squared_error: 0.2518\n",
      "2446/2446 [==============================] - 1s 238us/sample\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "cross_validated_models = []\n",
    "\n",
    "for best_model in best_models:\n",
    "    print(best_model[\"experiment\"])\n",
    "    cross_validation_results = []\n",
    "    count = 1\n",
    "\n",
    "    # Shuffle the dataset prior to initiating the validation\n",
    "    features, labels = shuffle_dataset(features, labels)\n",
    "    # We used k = 10 as it's the general number used in the literature\n",
    "    for train_index,test_index in KFold(n_splits=10, random_state=None, shuffle=False).split(features):\n",
    "        train_x, test_x = features[train_index], features[test_index]\n",
    "        train_y, test_y = labels[train_index], labels[test_index]\n",
    "\n",
    "        model = create_model(\n",
    "            best_model['experiment'],\n",
    "            best_model['units'], \n",
    "            best_model['activation_function'], \n",
    "            best_model['learning_rate'],\n",
    "            best_model['decay'],\n",
    "            best_model['momentum'])\n",
    "\n",
    "        history = train_model(model, train_x, train_y)\n",
    "        test_results = test_model(model, test_x, test_y)\n",
    "\n",
    "        cross_validation_results.append(\n",
    "            {\n",
    "                \"model_name\": best_model[\"model_name\"],\n",
    "                \"units\": best_model[\"units\"], \n",
    "                \"learning_rate\": best_model[\"learning_rate\"], \n",
    "                \"momentum\": best_model[\"momentum\"],\n",
    "                \"decay\": best_model[\"decay\"],\n",
    "                \"activation_function\": best_model[\"activation_function\"],\n",
    "                \"acc\": test_results[\"acc\"],\n",
    "                \"precision\": test_results[\"precision\"],\n",
    "                \"recall\": test_results[\"recall\"],\n",
    "                \"f_score\": test_results[\"f_score\"],\n",
    "                \"test_y\": test_results[\"test_y\"],\n",
    "                \"predicted_y\": test_results[\"predicted_y\"],\n",
    "                \"precision_curve\": test_results[\"precision_curve\"],\n",
    "                \"recall_curve\": test_results[\"recall_curve\"],\n",
    "                \"average_precision\": test_results[\"average_precision\"],\n",
    "                \"fpr_rf\": test_results[\"fpr_rf\"],\n",
    "                \"tpr_rf\": test_results[\"tpr_rf\"],\n",
    "                \"roc_auc_rf\": test_results[\"roc_auc_rf\"],\n",
    "            }\n",
    "        )\n",
    "        print(count)\n",
    "        count = count + 1\n",
    "\n",
    "    cross_validation_df = pd.DataFrame(cross_validation_results)\n",
    "\n",
    "    cross_validated_metrics = compute_c_validated_matrics(best_model, cross_validation_df)\n",
    "\n",
    "    cross_validated_models.append(cross_validated_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>model_name</th>\n",
       "      <th>units</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>momentum</th>\n",
       "      <th>decay</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>average_acc</th>\n",
       "      <th>acc_std_deviation</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>precision_std_deviation</th>\n",
       "      <th>average_recall</th>\n",
       "      <th>recall_std_deviation</th>\n",
       "      <th>average_fs_score</th>\n",
       "      <th>fs_score_std_deviation</th>\n",
       "      <th>average_precision_curve</th>\n",
       "      <th>roc_auc_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pmean_title</td>\n",
       "      <td>model_536</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.509403</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.509037</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.634015</td>\n",
       "      <td>0.239993</td>\n",
       "      <td>0.554616</td>\n",
       "      <td>0.098152</td>\n",
       "      <td>0.506056</td>\n",
       "      <td>0.507506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pmean_body</td>\n",
       "      <td>model_345</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.485282</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.486642</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.492128</td>\n",
       "      <td>0.132138</td>\n",
       "      <td>0.485461</td>\n",
       "      <td>0.070077</td>\n",
       "      <td>0.494943</td>\n",
       "      <td>0.484910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean_body</td>\n",
       "      <td>model_262</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.511652</td>\n",
       "      <td>0.019369</td>\n",
       "      <td>0.515596</td>\n",
       "      <td>0.026376</td>\n",
       "      <td>0.652726</td>\n",
       "      <td>0.211999</td>\n",
       "      <td>0.565947</td>\n",
       "      <td>0.067726</td>\n",
       "      <td>0.508931</td>\n",
       "      <td>0.512687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pmean_title_subtitle</td>\n",
       "      <td>model_224</td>\n",
       "      <td>75</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.506337</td>\n",
       "      <td>0.010696</td>\n",
       "      <td>0.510283</td>\n",
       "      <td>0.008516</td>\n",
       "      <td>0.376728</td>\n",
       "      <td>0.125269</td>\n",
       "      <td>0.428108</td>\n",
       "      <td>0.086794</td>\n",
       "      <td>0.505935</td>\n",
       "      <td>0.507157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean_title</td>\n",
       "      <td>model_472</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.507155</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.535063</td>\n",
       "      <td>0.027088</td>\n",
       "      <td>0.221213</td>\n",
       "      <td>0.206197</td>\n",
       "      <td>0.280832</td>\n",
       "      <td>0.209412</td>\n",
       "      <td>0.506208</td>\n",
       "      <td>0.507428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_title_subtitle</td>\n",
       "      <td>model_448</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.502044</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.884895</td>\n",
       "      <td>0.053198</td>\n",
       "      <td>0.640685</td>\n",
       "      <td>0.012382</td>\n",
       "      <td>0.502445</td>\n",
       "      <td>0.500393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             experiment model_name  units  learning_rate  momentum   decay  \\\n",
       "0           pmean_title  model_536     35         0.0001    0.1000  0.0001   \n",
       "1            pmean_body  model_345     75         0.0001    0.1000  0.1000   \n",
       "2             mean_body  model_262     75         0.0100    0.0100  0.0100   \n",
       "3  pmean_title_subtitle  model_224     75         0.1000    0.0010  0.0001   \n",
       "4            mean_title  model_472     35         0.0100    0.0001  0.0001   \n",
       "5   mean_title_subtitle  model_448     35         0.0100    0.0100  0.0001   \n",
       "\n",
       "  activation_function  average_acc  acc_std_deviation  average_precision  \\\n",
       "0                relu     0.509403           0.000578           0.509037   \n",
       "1                relu     0.485282           0.002313           0.486642   \n",
       "2                relu     0.511652           0.019369           0.515596   \n",
       "3                relu     0.506337           0.010696           0.510283   \n",
       "4                relu     0.507155           0.002024           0.535063   \n",
       "5                relu     0.502044           0.001735           0.502486   \n",
       "\n",
       "   precision_std_deviation  average_recall  recall_std_deviation  \\\n",
       "0                 0.001355        0.634015              0.239993   \n",
       "1                 0.008279        0.492128              0.132138   \n",
       "2                 0.026376        0.652726              0.211999   \n",
       "3                 0.008516        0.376728              0.125269   \n",
       "4                 0.027088        0.221213              0.206197   \n",
       "5                 0.001950        0.884895              0.053198   \n",
       "\n",
       "   average_fs_score  fs_score_std_deviation  average_precision_curve  \\\n",
       "0          0.554616                0.098152                 0.506056   \n",
       "1          0.485461                0.070077                 0.494943   \n",
       "2          0.565947                0.067726                 0.508931   \n",
       "3          0.428108                0.086794                 0.505935   \n",
       "4          0.280832                0.209412                 0.506208   \n",
       "5          0.640685                0.012382                 0.502445   \n",
       "\n",
       "   roc_auc_rf  \n",
       "0    0.507506  \n",
       "1    0.484910  \n",
       "2    0.512687  \n",
       "3    0.507157  \n",
       "4    0.507428  \n",
       "5    0.500393  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validated_df = pd.DataFrame(cross_validated_models)\n",
    "cross_validated_df = cross_validated_df[\n",
    "    [\n",
    "        \"experiment\", \n",
    "        \"model_name\",\n",
    "        \"units\",\n",
    "        \"learning_rate\", \n",
    "        \"momentum\",\n",
    "        \"decay\",\n",
    "        \"activation_function\",\n",
    "        \"average_acc\",\n",
    "        \"acc_std_deviation\",\n",
    "        \"average_precision\",\n",
    "        \"precision_std_deviation\",\n",
    "        \"average_recall\",\n",
    "        \"recall_std_deviation\",\n",
    "        \"average_fs_score\",\n",
    "        \"fs_score_std_deviation\",\n",
    "        \"average_precision_curve\",\n",
    "        \"roc_auc_rf\",\n",
    "    ]]\n",
    "cross_validated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validated_df.to_csv(\"../cross_validation/cross_validation_metrics.csv\", index= False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
